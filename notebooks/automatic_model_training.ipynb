{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c1eab0b3",
      "metadata": {
        "id": "c1eab0b3"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "882058c5",
      "metadata": {
        "id": "882058c5"
      },
      "source": [
        "This notebook demonstrates how to train custom openWakeWord models using pre-defined datasets and an automated process for dataset generation and training. While not guaranteed to always produce the best performing model, the methods shown in this notebook often produce baseline models with releatively strong performance.\n",
        "\n",
        "Manual data preparation and model training (e.g., see the [training models](training_models.ipynb) notebook) remains an option for when full control over the model development process is needed.\n",
        "\n",
        "At a high level, the automatic training process takes advantages of several techniques to try and produce a good model, including:\n",
        "\n",
        "- Early-stopping and checkpoint averaging (similar to [stochastic weight averaging](https://arxiv.org/abs/1803.05407)) to search for the best models found during training, according to the validation data\n",
        "- Variable learning rates with cosine decay and multiple cycles\n",
        "- Adaptive batch construction to focus on only high-loss examples when the model begins to converge, combined with gradient accumulation to ensure that batch sizes are still large enough for stable training\n",
        "- Cycical weight schedules for negative examples to help the model reduce false-positive rates\n",
        "\n",
        "See the contents of the `train.py` file for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08d031b",
      "metadata": {
        "id": "e08d031b"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee78c37",
      "metadata": {
        "id": "aee78c37"
      },
      "source": [
        "To begin, we'll need to install the requirements for training custom models. In particular, a relatively recent version of Pytorch and custom fork of the [piper-sample-generator](https://github.com/dscripka/piper-sample-generator) library for generating synthetic examples for the custom model.\n",
        "\n",
        "**Important Note!** Currently, automated model training is only supported on linux systems due to the requirements of the text to speech library used for synthetic sample generation (Piper). It may be possible to use Piper on Windows/Mac systems, but that has not (yet) been tested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b1227eb",
      "metadata": {
        "id": "4b1227eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fb64b02-a21f-41d4-c394-1db3580205a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'piper-sample-generator'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 124 (delta 28), reused 22 (delta 22), pack-reused 87 (from 1)\u001b[K\n",
            "Receiving objects: 100% (124/124), 1.03 MiB | 6.39 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "--2025-05-30 18:44:12--  https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184413Z&X-Amz-Expires=300&X-Amz-Signature=c87f417d446bbdb4dc04d91054c1e5aec593f8ef721b9bb487cc6c3867fd55ee&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-30 18:44:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/642029941/73f4af3c-7cf8-4547-a7b9-3bd29e7f3c33?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184413Z&X-Amz-Expires=300&X-Amz-Signature=c87f417d446bbdb4dc04d91054c1e5aec593f8ef721b9bb487cc6c3867fd55ee&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Den_US-libritts_r-medium.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 204089915 (195M) [application/octet-stream]\n",
            "Saving to: ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’\n",
            "\n",
            "piper-sample-genera 100%[===================>] 194.63M   191MB/s    in 1.0s    \n",
            "\n",
            "2025-05-30 18:44:14 (191 MB/s) - ‘piper-sample-generator/models/en_US-libritts_r-medium.pt’ saved [204089915/204089915]\n",
            "\n",
            "Collecting piper-phonemize\n",
            "  Downloading piper_phonemize-1.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (282 bytes)\n",
            "Downloading piper_phonemize-1.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: piper-phonemize\n",
            "Successfully installed piper-phonemize-1.1.0\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73587 sha256=82359d4c5787f8a5e1acf5c14fd7a47d7f57692d523a18349a5faaaee185da20\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n",
            "Cloning into 'openwakeword'...\n",
            "remote: Enumerating objects: 1186, done.\u001b[K\n",
            "remote: Counting objects: 100% (536/536), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 1186 (delta 441), reused 419 (delta 419), pack-reused 650 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1186/1186), 3.21 MiB | 17.01 MiB/s, done.\n",
            "Resolving deltas: 100% (731/731), done.\n",
            "Obtaining file:///content/openwakeword\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime<2,>=1.10.0 (from openwakeword==0.6.0)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tflite-runtime<3,>=2.8.0 (from openwakeword==0.6.0)\n",
            "  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: scipy<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (2.32.3)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (3.6.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openwakeword\n",
            "  Building editable for openwakeword (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openwakeword: filename=openwakeword-0.6.0-0.editable-py3-none-any.whl size=17494 sha256=543dfea19e033c6535d54d87f3104e32005a94c63465cbf34e8da9265397fc36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q6t82emg/wheels/0c/57/fb/ff0f65816c3a56a203bf97b5fba7bcc37a99e64ac8862bf609\n",
            "Successfully built openwakeword\n",
            "Installing collected packages: flatbuffers, tflite-runtime, humanfriendly, coloredlogs, onnxruntime, openwakeword\n",
            "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-1.22.0 openwakeword-0.6.0 tflite-runtime-2.14.0\n",
            "Collecting mutagen==1.47.0\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mutagen\n",
            "Successfully installed mutagen-1.47.0\n",
            "Collecting torchinfo==1.8.0\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting torchmetrics==1.2.0\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.6.0+cpu)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.2.0)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2025.5.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->torchmetrics==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.2.0) (3.0.2)\n",
            "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.14.3 torchmetrics-1.2.0\n",
            "Collecting speechbrain==0.5.14\n",
            "  Downloading speechbrain-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hyperpyyaml (from speechbrain==0.5.14)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (25.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.15.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.6.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.6.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.31.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2025.5.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.14) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml-0.18.12-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.14) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2025.4.26)\n",
            "Downloading speechbrain-0.5.14-py3-none-any.whl (519 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.0/519.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.12-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.12 ruamel.yaml.clib-0.2.12 speechbrain-0.5.14\n",
            "Collecting audiomentations==0.33.0\n",
            "  Downloading audiomentations-0.33.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (2.0.2)\n",
            "Collecting librosa!=0.10.0,<0.11.0,>=0.8.0 (from audiomentations==0.33.0)\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (1.15.3)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (5.2.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.61.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.13.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2025.4.26)\n",
            "Downloading audiomentations-0.33.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: librosa, audiomentations\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "Successfully installed audiomentations-0.33.0 librosa-0.10.2.post1\n",
            "Collecting torch-audiomentations==0.11.0\n",
            "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations==0.11.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.6.0+cpu)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.6.0+cpu)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations==0.11.0)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (5.2.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.61.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.13.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2025.5.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->torch-audiomentations==0.11.0) (1.3.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->torch-audiomentations==0.11.0) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2025.4.26)\n",
            "Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Building wheels for collected packages: julius\n",
            "  Building wheel for julius (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21966 sha256=c5b26010ede021e30ee17bb5e90784c748e99713a077edb81e0c9f26b1d2fe87\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built julius\n",
            "Installing collected packages: primePy, julius, torch-pitch-shift, torch-audiomentations\n",
            "Successfully installed julius-0.2.7 primePy-1.3 torch-audiomentations-0.11.0 torch-pitch-shift-1.2.5\n",
            "Collecting acoustics==0.2.6\n",
            "  Downloading acoustics-0.2.6.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (3.10.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.17.0)\n",
            "Requirement already satisfied: pandas>=0.15 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.2.2)\n",
            "Collecting tabulate (from acoustics==0.2.6)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (3.2.3)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Building wheels for collected packages: acoustics\n",
            "  Building wheel for acoustics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acoustics: filename=acoustics-0.2.6-py3-none-any.whl size=68221 sha256=f17cfad111260d5ffe553c8a83f98a47034bb9c1bf020c8ef3fd2a38b410d9cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/f0/b5/30a5d47708560f77b9167961c7ce13ab1ecf6ac352a3c077c2\n",
            "Successfully built acoustics\n",
            "Installing collected packages: tabulate, acoustics\n",
            "Successfully installed acoustics-0.2.6 tabulate-0.9.0\n",
            "Requirement already satisfied: tensorflow_probability==0.25.0 in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (2.0.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (5.2.1)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.25.0) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.25.0) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.25.0) (1.17.2)\n",
            "Collecting onnx_tf==1.10.0\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Collecting onnx>=1.10.2 (from onnx_tf==1.10.0)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from onnx_tf==1.10.0) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx_tf==1.10.0)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (5.29.4)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons->onnx_tf==1.10.0) (25.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx_tf==1.10.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, onnx, tensorflow-addons, onnx_tf\n",
            "Successfully installed onnx-1.18.0 onnx_tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Collecting pronouncing==0.2.0\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing==0.2.0)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting importlib-metadata>=5 (from cmudict>=0.4.0->pronouncing==0.2.0)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing==0.2.0) (3.21.0)\n",
            "Downloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Building wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6340 sha256=7aff40b98ce890a87dfacb1a9be23494aa312f656e2f75f358bf5597e6cd3706\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/81/fd/7edbf09827c7a7e2666e870b4c5c6b46c7ebd5defa399698bd\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: importlib-metadata, cmudict, pronouncing\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "Successfully installed cmudict-1.0.32 importlib-metadata-8.7.0 pronouncing-0.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "6872b91320db4518a659dd866d3baf50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.14.6\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (20.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.14.6)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.14.6)\n",
            "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.31.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2025.4.26)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.14.6)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
            "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m898.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.0\n",
            "    Uninstalling fsspec-2025.5.0:\n",
            "      Successfully uninstalled fsspec-2025.5.0\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 xxhash-3.5.0\n",
            "Collecting deep-phonemizer==0.0.19\n",
            "  Downloading deep-phonemizer-0.0.19.tar.gz (29 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.6.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (6.0.2)\n",
            "Collecting tensorboard (from deep-phonemizer==0.0.19)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2025.4.26)\n",
            "Collecting wheel>=0.38.0 (from deep-phonemizer==0.0.19)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2023.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->deep-phonemizer==0.0.19) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (5.29.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.17.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->deep-phonemizer==0.0.19)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->deep-phonemizer==0.0.19)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->deep-phonemizer==0.0.19) (3.0.2)\n",
            "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deep-phonemizer\n",
            "  Building wheel for deep-phonemizer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.19-py3-none-any.whl size=33357 sha256=f3e96f9fb88a9860d2bfedabeae2fbc69c23dd7153b9ce9a7bb4590c9c8f3c98\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/cc/01/1c74a1f4e6ba31a42bb82f4e3d852e2f23236fe3e5d589dcf3\n",
            "Successfully built deep-phonemizer\n",
            "Installing collected packages: wheel, werkzeug, tensorboard-data-server, tensorboard, deep-phonemizer\n",
            "Successfully installed deep-phonemizer-0.0.19 tensorboard-2.19.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3 wheel-0.45.1\n",
            "--2025-05-30 18:45:18--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184518Z&X-Amz-Expires=300&X-Amz-Signature=978531a3c5cf450792ed9ff3b6db1487d0b54fdbf5ee7481df821630fe5c55b6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-30 18:45:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184518Z&X-Amz-Expires=300&X-Amz-Signature=978531a3c5cf450792ed9ff3b6db1487d0b54fdbf5ee7481df821630fe5c55b6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1326578 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.26M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-05-30 18:45:18 (19.6 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’ saved [1326578/1326578]\n",
            "\n",
            "--2025-05-30 18:45:19--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184519Z&X-Amz-Expires=300&X-Amz-Signature=a8d31f91951504a388503e061436295bc12894d4e21216ab6f2d5454e91ed3aa&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-30 18:45:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184519Z&X-Amz-Expires=300&X-Amz-Signature=a8d31f91951504a388503e061436295bc12894d4e21216ab6f2d5454e91ed3aa&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330312 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.27M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-05-30 18:45:19 (19.2 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’ saved [1330312/1330312]\n",
            "\n",
            "--2025-05-30 18:45:19--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/6b613c12-b693-4220-82d5-01be396893d9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184519Z&X-Amz-Expires=300&X-Amz-Signature=1b41485b95ac24733336c7e880f85a49a5531f57173ee558ffba0e0e51ebf038&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-30 18:45:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/6b613c12-b693-4220-82d5-01be396893d9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184519Z&X-Amz-Expires=300&X-Amz-Signature=1b41485b95ac24733336c7e880f85a49a5531f57173ee558ffba0e0e51ebf038&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1087958 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-05-30 18:45:19 (17.4 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’ saved [1087958/1087958]\n",
            "\n",
            "--2025-05-30 18:45:20--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184520Z&X-Amz-Expires=300&X-Amz-Signature=1d254f17e9bc6f8a6a3e074a0a7a0499967b254ee48cab72949101873d6cb689&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-30 18:45:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250530%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250530T184520Z&X-Amz-Expires=300&X-Amz-Signature=1d254f17e9bc6f8a6a3e074a0a7a0499967b254ee48cab72949101873d6cb689&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092516 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-05-30 18:45:20 (16.7 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’ saved [1092516/1092516]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Environment setup\n",
        "\n",
        "# install piper-sample-generator (currently only supports linux systems)\n",
        "!git clone https://github.com/rhasspy/piper-sample-generator\n",
        "!wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
        "!pip install piper-phonemize\n",
        "!pip install webrtcvad\n",
        "\n",
        "# install openwakeword (full installation to support training)\n",
        "!git clone https://github.com/dscripka/openwakeword\n",
        "!pip install -e ./openwakeword\n",
        "!cd openwakeword\n",
        "\n",
        "# install other dependencies\n",
        "!pip install mutagen==1.47.0\n",
        "!pip install torchinfo==1.8.0\n",
        "!pip install torchmetrics==1.2.0\n",
        "!pip install speechbrain==0.5.14\n",
        "!pip install audiomentations==0.33.0\n",
        "!pip install torch-audiomentations==0.11.0\n",
        "!pip install acoustics==0.2.6\n",
        "!pip install tensorflow_probability==0.25.0 #0.16.0 kind of worked, but failed at last training (before conversion)\n",
        "!pip install onnx_tf==1.10.0\n",
        "!pip install pronouncing==0.2.0\n",
        "!pip install datasets==2.14.6\n",
        "!pip install deep-phonemizer==0.0.19\n",
        "\n",
        "# Download required models (workaround for Colab)\n",
        "import os\n",
        "os.makedirs(\"./openwakeword/openwakeword/resources/models\",exist_ok=True)\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx -O ./openwakeword/openwakeword/resources/models/embedding_model.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite -O ./openwakeword/openwakeword/resources/models/embedding_model.tflite\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx -O ./openwakeword/openwakeword/resources/models/melspectrogram.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite -O ./openwakeword/openwakeword/resources/models/melspectrogram.tflite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c1056e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:42:01.183840Z",
          "start_time": "2023-09-04T13:41:59.752153Z"
        },
        "id": "d4c1056e"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "# Modify generate_samples.py to explicitly set weights_only=False\n",
        "!sed -i 's/torch\\.load(model_path,weights_only=False)/torch.load(model_path, weights_only=False)/g' /content/piper-sample-generator/generate_samples.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import yaml\n",
        "import datasets\n",
        "import scipy\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d7a05a",
      "metadata": {
        "id": "e9d7a05a"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52f75cc",
      "metadata": {
        "id": "c52f75cc"
      },
      "source": [
        "When training new openWakeWord models using the automated procedure, four specific types of data are required:\n",
        "\n",
        "1) Synthetic examples of the target word/phrase generated with text-to-speech models\n",
        "\n",
        "2) Synthetic examples of adversarial words/phrases generated with text-to-speech models\n",
        "\n",
        "3) Room impulse reponses and noise/background audio data to augment the synthetic examples and make them more realistic\n",
        "\n",
        "4) Generic \"negative\" audio data that is very unlikely to contain examples of the target word/phrase in the context where the model should detect it. This data can be the original audio data, or precomputed openWakeWord features ready for model training.\n",
        "\n",
        "5) Validation data to use for early-stopping when training the model.\n",
        "\n",
        "For the purposes of this notebook, all five of these sources will either be generated manually or can be obtained from HuggingFace thanks to their excellent `datasets` library and extremely generous hosting policy. Also note that while only a portion of some datasets are downloaded, for the best possible performance it is recommended to download the entire dataset and keep a local copy for future training runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25a93b1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T01:07:17.746749Z",
          "start_time": "2023-09-04T01:07:17.740846Z"
        },
        "id": "d25a93b1"
      },
      "outputs": [],
      "source": [
        "# Download room impulse responses collected by MIT\n",
        "# https://mcdermottlab.mit.edu/Reverb/IR_Survey.html\n",
        "\n",
        "output_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
        "\n",
        "# Save clips to 16-bit PCM wav files\n",
        "for row in tqdm(rir_dataset):\n",
        "    name = row['audio']['path'].split('/')[-1]\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0e178b",
      "metadata": {
        "id": "2c0e178b"
      },
      "outputs": [],
      "source": [
        "## Download noise and background audio\n",
        "\n",
        "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
        "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
        "# For full-scale training, it's recommended to download the entire dataset from\n",
        "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
        "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
        "\n",
        "if not os.path.exists(\"audioset\"):\n",
        "    os.mkdir(\"audioset\")\n",
        "\n",
        "fname = \"bal_train09.tar\"\n",
        "out_dir = f\"audioset/{fname}\"\n",
        "link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
        "!wget -O {out_dir} {link}\n",
        "!cd audioset && tar -xvf bal_train09.tar\n",
        "\n",
        "output_dir = \"./audioset_16k\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "# Convert audioset files to 16khz sample rate\n",
        "audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"audioset/audio\").glob(\"**/*.flac\")]})\n",
        "audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "for row in tqdm(audioset_dataset):\n",
        "    name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "# Free Music Archive dataset (https://github.com/mdeff/fma)\n",
        "output_dir = \"./fma\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "n_hours = 1  # use only 1 hour of clips for this example notebook, recommend increasing for full-scale training\n",
        "for i in tqdm(range(n_hours*3600//30)):  # this works because the FMA dataset is all 30 second clips\n",
        "    row = next(fma_dataset)\n",
        "    name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "    scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "    i += 1\n",
        "    if i == n_hours*3600//30:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01ec467",
      "metadata": {
        "id": "d01ec467"
      },
      "outputs": [],
      "source": [
        "# Download pre-computed openWakeWord features for training and validation\n",
        "\n",
        "# training set (~2,000 hours from the ACAV100M Dataset)\n",
        "# See https://huggingface.co/datasets/davidscripka/openwakeword_features for more information\n",
        "!wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
        "\n",
        "# validation set for false positive rate estimation (~11 hours)\n",
        "!wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe82647",
      "metadata": {
        "id": "cfe82647"
      },
      "source": [
        "# Define Training Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e71329",
      "metadata": {
        "id": "b2e71329"
      },
      "source": [
        "For automated model training openWakeWord uses a specially designed training script and a [YAML](https://yaml.org/) configuration file that defines all of the information required for training a new wake word/phrase detection model.\n",
        "\n",
        "It is strongly recommended that you review [the example config file](../examples/custom_model.yml), as each value is fully documented there. For the purposes of this notebook, we'll read in the YAML file to modify certain configuration parameters before saving a new YAML file for training our example model. Specifically:\n",
        "\n",
        "- We'll train a detection model for the phrase \"hey sebastian\"\n",
        "- We'll only generate 5,000 positive and negative examples (to save on time for this example)\n",
        "- We'll only generate 1,000 validation positive and negative examples for early stopping (again to save time)\n",
        "- The model will only be trained for 10,000 steps (larger datasets will benefit from longer training)\n",
        "- We'll reduce the target metrics to account for the small dataset size and limited training.\n",
        "\n",
        "On the topic of target metrics, there are *not* specific guidelines about what these metrics should be in practice, and you will need to conduct testing in your target deployment environment to establish good thresholds. However, from very limited testing the default values in the config file (accuracy >= 0.7, recall >= 0.5, false-positive rate <= 0.2 per hour) seem to produce models with reasonable performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0b6e4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T18:11:33.893397Z",
          "start_time": "2023-09-04T18:11:33.878938Z"
        },
        "id": "fb0b6e4f"
      },
      "outputs": [],
      "source": [
        "# Load default YAML config file for training\n",
        "config = yaml.load(open(\"openwakeword/examples/custom_model.yml\", 'r').read(), yaml.Loader)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482cf2d0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T15:07:00.859210Z",
          "start_time": "2023-09-04T15:07:00.841472Z"
        },
        "id": "482cf2d0"
      },
      "outputs": [],
      "source": [
        "# Modify values in the config and save a new version\n",
        "\n",
        "config[\"target_phrase\"] = [\"atlas\"]\n",
        "config[\"model_name\"] = config[\"target_phrase\"][0].replace(\" \", \"_\")\n",
        "config[\"n_samples\"] = 200000\n",
        "config[\"n_samples_val\"] = 20000\n",
        "config[\"steps\"] = 100000\n",
        "config[\"target_accuracy\"] = 0.75\n",
        "config[\"target_recall\"] = 0.25\n",
        "\n",
        "config[\"background_paths\"] = ['./audioset_16k', './fma']  # multiple background datasets are supported\n",
        "config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
        "config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
        "\n",
        "with open('my_model.yaml', 'w') as file:\n",
        "    documents = yaml.dump(config, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6b2ab0",
      "metadata": {
        "id": "aa6b2ab0"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51202c0",
      "metadata": {
        "id": "a51202c0"
      },
      "source": [
        "With the data downloaded and training configuration set, we can now start training the model. We'll do this in parts to better illustrate the sequence, but you can also execute every step at once for a fully automated process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01531fa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:50:08.803326Z",
          "start_time": "2023-09-04T13:50:06.790241Z"
        },
        "id": "f01531fa"
      },
      "outputs": [],
      "source": [
        "# Step 1: Generate synthetic clips\n",
        "# For the number of clips we are using, this should take ~10 minutes on a free Google Colab instance with a T4 GPU\n",
        "# If generation fails, you can simply run this command again as it will continue generating until the\n",
        "# number of files meets the targets specified in the config file\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --generate_clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afeedae4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T13:56:08.781018Z",
          "start_time": "2023-09-04T13:55:40.203515Z"
        },
        "id": "afeedae4"
      },
      "outputs": [],
      "source": [
        "# Step 2: Augment the generated clips\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --augment_clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ad81ea0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-04T15:11:14.742260Z",
          "start_time": "2023-09-04T15:07:03.755159Z"
        },
        "id": "9ad81ea0"
      },
      "outputs": [],
      "source": [
        "# Step 3: Train model\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSKWWLalnYzR",
      "metadata": {
        "id": "JSKWWLalnYzR"
      },
      "outputs": [],
      "source": [
        "# Step 4 (Optional): On Google Colab, sometimes the .tflite model isn't saved correctly\n",
        "# If so, run this cell to retry\n",
        "\n",
        "# Manually save to tflite as this doesn't work right in colab\n",
        "def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
        "    \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
        "    # imports\n",
        "    import onnx\n",
        "    import logging\n",
        "    import tempfile\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Convert to tflite from onnx model\n",
        "    onnx_model = onnx.load(onnx_model_path)\n",
        "    tf_rep = prepare(onnx_model, device=\"CPU\")\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        logging.info(f\"####\\nSaving tflite mode to '{output_path}'\")\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "    return None\n",
        "\n",
        "convert_onnx_to_tflite(f\"my_custom_model/{config['model_name']}.onnx\", f\"my_custom_model/{config['model_name']}.tflite\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9OyUW3ltOSs",
      "metadata": {
        "id": "f9OyUW3ltOSs"
      },
      "source": [
        "After the model finishes training, the auto training script will automatically convert it to ONNX and tflite versions, saving them as `my_custom_model/<model_name>.onnx/tflite` in the present working directory, where `<model_name>` is defined in the YAML training config file. Either version can be used as normal with `openwakeword`. I recommend testing them with the [`detect_from_microphone.py`](https://github.com/dscripka/openWakeWord/blob/main/examples/detect_from_microphone.py) example script to see how the model performs!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}